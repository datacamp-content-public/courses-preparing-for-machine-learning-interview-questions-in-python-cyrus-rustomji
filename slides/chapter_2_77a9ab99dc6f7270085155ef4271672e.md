---
title: Insert title here
key: 77a9ab99dc6f7270085155ef4271672e

---
## Breaking down Linear Regression

```yaml
type: "TitleSlide"
key: "a926230204"
```

`@lower_third`

name: Cyrus Rustomji
title: Instructor at DataCamp


`@script`
Hello everyone and welcome to Preparing for Machine Learning Interview Questions in Python.
In this first lesson, we will learn how to spot if an interviewer is asking questions on a Linear Regression model,
how to create one in Python,
and how to regularize it.


---
## Linear Regression Overview

```yaml
type: "FullImageSlide"
key: "208994397a"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4634/datasets/364d9c56d605648ca7aa109c87b8475df9cb9a50/lr.png)


`@script`
So first,
a quick overview,

a linear regression model is a model that summarizes and studies relationships between two continuous variables, predictor variables (denoted as X) vs. a response variable (denoted as y).

As you know, the vertical axis is the response variable, whereas the horizontal axis are the predictor variables.


---
## What is Regularization?

```yaml
type: "FullImageSlide"
key: "8ddd96b8fe"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4634/datasets/32a76df1b08131494c4aa7a8b613b5776ae05c3c/Overfitting.png)


`@script`
What is regularization?

Regularization helps fit your model to your dataset. In this picture, we would like our model to be the middle graph. However, when initially running a linear regression, that may not be the case and your model is usually underfit like the graph on the left.

This means that there are many outliers, and it is too simple to explain the variance. Once you regularize your model, there is a chance of overfitting like the model on the right which forcefits all data to your model.

This is not good because when we're adding new data to the model it will only fit similar data points from the old dataset and not new datasets it has not seen.

This is why regularization is important in acheving the optimal model.


---
## Regularization Overview

```yaml
type: "FullImageSlide"
key: "733505f2dd"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4634/datasets/1bb4b799a867b06146650c2b9fe58beea704ae11/elastic_net.jpg)


`@script`
Here is a quick overview, for regularizing a linear regression model.

The left is the L1 norm which drops or keeps the predictor variables if it will better the models accuracy,

while the right L2 norm will weight predictor variables on a scale of 0 - 1 of how important each metric is.


---
## Elastic Net Overview

```yaml
type: "FullImageSlide"
key: "fa01e27650"
```

`@part1`
![](https://assets.datacamp.com/production/repositories/4634/datasets/3b9e460a5e866e9d08bc9302217da98d088614a0/true_elastic_net.png)


`@script`
From the previous slide, we were able to understand what and how L1 and L2 norms work. Now, we are going to understand the combination of the two. The elastic net.

The elastic net in this example is the orange circle.

It takes aspects from the L1 norms which drops or keeps the predictor variables if it will better the models accuracy, and also takes aspects from the L2 norm which weights the predictor variables on a scale of 0 - 1 of how important each metric is.

Drawing this graph and explaining what you're drawing for interviewers during an interview will show that you understand the interworkings of the L1 norm, L2 norm, and elastic net.


---
## Q & A

```yaml
type: "FullCodeSlide"
key: "15b0cab39d"
```

`@part1`
Which dataset would best fit a linear regression?

a. Predicting if an album will go platinum or not

b. Recognizing digits

c. Predicting the US immigration quota

d. Uber price prediction


Answer C {{2}}


`@script`
Here is a quick Q&A on Which dataset would best fit a linear regression? And I'll pause for a bit, so y'all can figure it out.

(Pause for 10 seconds)

The correct answer is C because it is trying to predict a number whereas A is a classification problem, B is a computer vision problem, and D requires seasonal data making it more complex than a linear regression.


---
## Building a Linear Regression Model

```yaml
type: "FullCodeSlide"
key: "2d1eba009c"
center_content: true
```

`@part1`
```
from sklearn linear model import LinearRegression
X = df[‘X1’,’X2’,’X3’]
y = df[‘y’]
lr1 = LinearRegression()
lr1.fit(X,y)
lr1.score(X,y)
```


`@script`
This is how to build a Linear Regression model when asked to build one during an interview.

First, we import sklearn's LinearRegression, then set X, our predictor variables to columns in our dataframe, labeled df. And set y to our response variable. Then we fit our model to a linearregression and find the score of the model.

By finding the score of the model, we can see if we need to regularize our model or not. This score is dependent on the study that you are trying to create.


---
## Building Elastic Net Metrics

```yaml
type: "FullCodeSlide"
key: "e485feeb52"
```

`@part1`
```
from sklearn.linear_model import ElasticNet
alpha = 1e-5
enet = ElasticNet(alpha=alpha)
y_pred_enet = enet.fit(X_test, y_test)
y_pred_enet.score(X_test,y_test)
```


`@script`
This is how to build elastic net metrics when asked to build one during an interview.

First, we import ElasticNet from sklearn. Then we set the alpha, which is the cv error and we would like this minimized in order to not under or overfit our model to our data. Then we fit and get the score of our model in hoping to generate a higher and more accurate score compared to our linear regression.


---
## Let's practice!

```yaml
type: "FinalSlide"
key: "a629224bde"
```

`@script`
Now let's practice and see if you can answer more questions relating to linear regression models and build one from scratch.

